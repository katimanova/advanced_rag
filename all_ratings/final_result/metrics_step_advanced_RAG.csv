,Base rag,Base rag gpt,RAG+_1_gigachat,RAG+_1_gpt_3.5,RAG+_2_gpt_3.5,RAG+_3_gpt_3.5,RAG+_4_gpt_3.5,RAG+_5_gpt_3.5,RAG+_6_gpt_3.5
faithfulness,0.8392857142857143,0.8547348484848485,0.9255208333333333,0.9349296536796537,0.8158541194255479,0.7167261904761905,0.7167261904761905,0.8777777777777778,0.8547348484848485
answer_relevancy,0.7117285974977678,0.8392723722802526,0.6979315389235808,0.8321466978233721,0.7921191841790418,0.7511503345049998,0.7511503345049998,0.8428273767002373,0.8392723722802526
context_precision,0.9999999998999999,0.9999999998999999,0.9999999998999999,0.9999999998999999,0.9999999998999999,0.9999999998999999,0.9999999998999999,0.9999999998999999,0.9999999998999999
context_relevancy,0.7549182139699382,0.7988837312113175,0.7802055702917772,0.7672745358090186,0.7644009725906278,0.7837975243147658,0.7837975243147658,0.7924182139699382,0.7988837312113175
answer_similarity,0.9239248937076107,0.9262469345759073,0.914837818755752,0.9273572081606503,0.9256356560724038,0.9209845895268874,0.9209845895268874,0.9292591445031584,0.9262469345759073
bleu_score,0.09352241379310346,0.06831206896551725,0.10175172413793104,0.0660948275862069,0.0675603448275862,0.060194827586206895,0.060194827586206895,0.07025,0.06831206896551725
sim-spacy,0.8577893882349992,0.8866032334194653,0.8488994219161046,0.8744373634478348,0.8820842415341728,0.8681038509810473,0.8681038509810473,0.8982650069219804,0.8866032334194653
cos-sim-TF-IDF,0.2652241379310345,0.2833896808462957,0.3070288520887098,0.2698397433551506,0.27425032250890835,0.26983801884829917,0.26983801884829917,0.2900732708957009,0.2833896808462957
cos-sim-BertModel,0.9822290237931036,0.9827383587931033,0.9796679246551725,0.9808290391379311,0.9805875151724139,0.9796932065517242,0.9796932065517242,0.9827427796551724,0.9827383587931033
Human_score,0.6896551724137931,0.7241379310344828,,0.8275862068965517,,0.9396551724137931,0.7586206896551724,0.8706896551724138,
