,Base rag,RAG standart_split 1800,RAG standart_split 1200/100,My html_split 100-220 token,html_split 1800 / 100,html_split 1000 / 100
faithfulness,0.8392857142857143,0.7797178130511463,0.8507575757575758,0.9314814814814815,0.8697916666666666,0.9230769230769231
answer_relevancy,0.7117285974977678,0.6755310330152717,0.6331001888692553,0.5794470353161624,0.5007340969007608,0.6052437588478589
context_precision,0.9999999998999999,0.9999999998999999,0.9999999998999999,0.9999999998999999,0.9999999998999999,0.9999999998999999
context_relevancy,0.7549182139699382,0.7937113174182141,0.8017572944297082,0.7744584438549956,0.8118147656940761,0.7924182139699382
answer_similarity,0.9239248937076107,0.9123504761142155,0.9145864611623452,0.9090154973074307,0.9086204247989046,0.9221207955250323
bleu_score,0.09352241379310346,0.07504655172413793,0.08070000000000001,0.09635862068965517,0.09760689655172414,0.12198793103448274
sim-spacy,0.8577893882349992,0.817983531619502,0.807410612645777,0.8290061026149991,0.8374423863708552,0.8447414150741912
cos-sim-TF-IDF,0.2652241379310345,0.22604792159679593,0.25205685527741006,0.2565707829317841,0.24146079296783224,0.27783558781193257
cos-sim-BertModel,0.9822290237931036,0.9704517820689654,0.9685797031034484,0.9757609431034482,0.9772887441379311,0.9812855193103448
human,,0.5172413793103449,,,,
