,Base rag,standart_split - rag_step_back,html_split - rag_fusion,html_split - rag_multi_query,html_split - rag_step_back
faithfulness,0.8392857142857143,0.8828571428571428,0.9345238095238094,0.8022988505747126,0.894144144144144
answer_relevancy,0.7117285974977678,0.7758362528362248,0.7816934828862009,0.6710172157529072,0.8337223292621189
context_precision,0.9999999998999999,0.9999999998999999,0.9999999998999999,0.9999999998999999,0.9999999998999999
context_relevancy,0.7549182139699382,0.7980216622458002,0.8031940760389037,0.7876768346595934,0.793711317418214
answer_similarity,0.9239248937076107,0.932192798782735,0.9259642137957513,0.9167606537918076,0.9291578377839675
bleu_score,0.09352241379310346,0.09251379310344827,0.09945172413793103,0.09748275862068966,0.09231724137931034
sim-spacy,0.8577893882349992,0.8821712493262063,0.8549429042609025,0.8341149545852649,0.8627691821015259
cos-sim-TF-IDF,0.2652241379310345,0.29005119548036357,0.2864052878091177,0.24715692307103324,0.2781855048509431
cos-sim-BertModel,0.9822290237931036,0.9842352298275862,0.9817012910344829,0.9795376875862069,0.9843831927586206
