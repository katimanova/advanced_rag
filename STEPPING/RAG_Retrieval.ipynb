{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k_count\n",
    "Количество возвращаемых retrieval фрагментов.\n",
    "\n",
    "Выбор параметров для поиска и настройки `Retriever` зависит от конкретной задачи и требований к системе. Вот несколько рекомендаций по выбору `search_type`, значений параметров `k`, `lambda_mult` и других параметров:\n",
    "\n",
    "1. **`search_type`**:\n",
    "    - **`similarity`**: Используйте этот тип поиска, если вам нужно найти документы, которые наиболее похожи на запрос. Это стандартный выбор для большинства задач.\n",
    "    - **`mmr`**: Используйте максимальную маргинальную релевантность (MMR) для увеличения разнообразия возвращаемых результатов. Этот тип поиска полезен, когда нужно избегать получения слишком похожих документов.\n",
    "    - **`similarity_score_threshold`**: Используйте этот тип поиска, если вам важно, чтобы возвращаемые документы превышали определенный порог релевантности. Это может быть полезно для задач, требующих высоко релевантных ответов.\n",
    "\n",
    "2. **`k` (количество возвращаемых документов)**:\n",
    "    - Значение по умолчанию составляет 4, но оптимальное значение может варьироваться в зависимости от задачи. Если требуется больше контекста или более полное покрытие темы, можно увеличить `k`. Например, `k=5` или `k=10`.\n",
    "    - Для более точных запросов или ограниченного объема данных может быть достаточно меньшего значения, например, `k=3`.\n",
    "\n",
    "3. **`lambda_mult` (только для `mmr` поиска)**:\n",
    "    - Этот параметр регулирует разнообразие результатов. Значение по умолчанию составляет 0.5, что является компромиссом между релевантностью и разнообразием.\n",
    "    - Для максимального разнообразия установите `lambda_mult` ближе к 0. Для минимального разнообразия, но максимальной релевантности установите `lambda_mult` ближе к 1.\n",
    "    - Оптимальное значение зависит от задачи: для широкого охвата информации можно установить `lambda_mult=0.25`, а для узконаправленных запросов – ближе к 0.75.\n",
    "\n",
    "4. **Другие параметры**:\n",
    "    - **`fetch_k`**: Этот параметр определяет количество документов, которые передаются алгоритму MMR для выбора наиболее релевантных и разнообразных результатов. Значение по умолчанию — 20, и его можно оставить без изменений, если нет специфических требований.\n",
    "    - **`score_threshold`**: Устанавливайте только для `similarity_score_threshold` типа поиска. Зависит от порога релевантности, который вы хотите задать.\n",
    "    - **`filter`**: Используйте для фильтрации документов по метаданным, если у вас есть дополнительные критерии отбора.\n",
    "\n",
    "\n",
    "\n",
    "#### Значение `score_threshold`:\n",
    "\n",
    "- **Низкое значение (< 0.3)**: Используйте, если вы хотите получить как можно больше результатов, даже если они могут быть менее релевантными. Подходит для задач, где важен широкий охват информации.\n",
    "- **Среднее значение (0.3 - 0.7)**: Используйте для достижения баланса между количеством и качеством результатов. Подходит для задач, где требуется умеренная точность и достаточное количество результатов.\n",
    "- **Высокое значение (> 0.7)**: Используйте, если вам нужны только высоко релевантные результаты. Подходит для задач, где важна высокая точность, и количество результатов может быть ограничено.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![structure.png](../Schemes/Retrieval_serch_type.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разбиваем документы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from necessity import *\n",
    "\n",
    "# LangSmith\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Retrieval_testing_k_3_html_split\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# получаем смысловую разбивку всех документов\n",
    "# splits = split_documents_my_html()\n",
    "splits = split_documents_html(chunk_size=1000, chunk_overlap=100)\n",
    "# splits = split_documents_standart(chunk_size=1000, chunk_overlap=100)\n",
    "\n",
    "# индексируем\n",
    "embeddings_model = GigaChatEmbeddings(scope=\"GIGACHAT_API_PERS\", verify_ssl_certs=False)\n",
    "db = Chroma.from_documents(documents=splits, embedding=embeddings_model)\n",
    "\n",
    "# подключаем llm\n",
    "llm = GigaChat(model='GigaChat-Plus', verify_ssl_certs=False, scope=\"GIGACHAT_API_PERS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Устанавливаем ретриевер для поиска контекста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ________________________ 1 _________________________\n",
    "retriever_similarity_1 = db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={'k': 1}\n",
    ")\n",
    "\n",
    "retriever_mmr_1 = db.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={'k': 1, 'lambda_mult': 0.25}\n",
    ")\n",
    "\n",
    "retriever_similarity_score_threshold_1 = db.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={'k': 1, 'score_threshold': 0.7}\n",
    ")\n",
    "\n",
    "# ________________________ 3 _________________________\n",
    "\n",
    "retriever_similarity_3 = db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={'k': 3}\n",
    ")\n",
    "\n",
    "retriever_mmr_3 = db.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={'k': 3, 'lambda_mult': 0.25}\n",
    ")\n",
    "\n",
    "retriever_similarity_score_threshold_3 = db.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={'k': 3, 'score_threshold': 0.7}\n",
    ")\n",
    "\n",
    "# ________________________ 7 _________________________\n",
    "\n",
    "retriever_similarity_7 = db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={'k': 7}\n",
    ")\n",
    "\n",
    "retriever_mmr_7 = db.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={'k': 7, 'lambda_mult': 0.25}\n",
    ")\n",
    "\n",
    "retriever_similarity_score_threshold_7 = db.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={'score_threshold': 0.6},\n",
    "    k=7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"\"\"Вы являетесь помощником в выполнении поиска ответов на вопросы. Используйте приведенные ниже фрагменты извлеченного контекста, чтобы ответить на вопрос. Если вы не знаете ответа, просто скажите, что вы не знаете.\n",
    "        Test_name: retriever_mmr_3\n",
    "        Question: {question} \n",
    "        Context: {context} \n",
    "        Answer:\"\"\")\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever_similarity_3, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_1 = rag_chain.invoke(\"При принятии пользовательских соглашений, кому еще попадают мои данные?\")\n",
    "answer_2 = rag_chain.invoke(\"Я не пользовалась кредиткой год, но у меня там лежат мои 800 рублей, я могу их как-то вернуть?\")\n",
    "answer_3 = rag_chain.invoke(\"Какие документы потребуются, если открывать счет для нотариуса, занимающегося частной практикой? Может ли нотариус быть иностранцем при этом?\")\n",
    "answer_4 = rag_chain.invoke(\"Какой минимум страховой выплаты мне вернут, если моя страховая сумма = 50 000 долларов?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы\n",
    "Большое количестов контекста не влияет положительно на результат, оптимальное колличесвто - 3.  \n",
    "\n",
    "Метод similarity_score_threshold не показал себя - опустим его"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k_count_3_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from necessity import *\n",
    "\n",
    "# LangSmith\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Retrieval_testing_k_count_3_similarity_html_split\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_similarity_3 = db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={'k': 3}\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Вы являетесь помощником в выполнении поиска ответов на вопросы. Используйте приведенные ниже фрагменты извлеченного контекста, чтобы ответить на вопрос. Если вы не знаете ответа, просто скажите, что вы не знаете.\n",
    "        Test_name: retriever_similarity_3\n",
    "        Question: {question} \n",
    "        Context: {context} \n",
    "        Answer:\"\"\")\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever_similarity_3, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка Датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../dataset.csv')\n",
    "\n",
    "df['answer'] = df['question'].apply(lambda x: rag_chain.invoke(x.strip()))\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../rag_answer/rag_step_retriever/html_split/rag_3_similarity.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-Rank from Cohere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравнение ContextualCompressionRetriever и co.rerank\n",
    "\n",
    "Функция `compression_retriever.get_relevant_documents(query)` и функция `co.rerank()` имеют разные цели и используют разные подходы для обработки и ранжирования документов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variant 1 compressor = CohereRerank()\n",
    "\n",
    "### ContextualCompressionRetriever\n",
    "\n",
    "`ContextualCompressionRetriever` используется для получения релевантных документов с применением компрессии. Компрессия здесь означает отбор наиболее значимых частей из документов для ответа на конкретный запрос. `CohereRerank` используется как компрессор для выбора и компрессии этих частей.\n",
    "\n",
    "### Пример работы ContextualCompressionRetriever:\n",
    "\n",
    "1. **Поиск документов**: Исходный `retriever` используется для поиска документов по запросу.\n",
    "2. **Компрессия документов**: Компрессор (в данном случае `CohereRerank`) применяется для извлечения наиболее релевантных частей из найденных документов.\n",
    "3. **Возвращение документов**: Компрессор возвращает сжатые версии документов, которые считаются наиболее релевантными для запроса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from necessity import *\n",
    "\n",
    "# LangSmith\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"TEST_FINAL_COMPRESSOR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI \n",
    "llm=ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\")\n",
    "embeddings_model = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# получаем смысловую разбивку всех документов\n",
    "# splits = split_documents_my_html()\n",
    "splits = split_documents_html(chunk_size=1000, chunk_overlap=100)\n",
    "# splits = split_documents_standart(chunk_size=1000, chunk_overlap=100)\n",
    "\n",
    "# индексируем\n",
    "# embeddings_model = GigaChatEmbeddings(scope=\"GIGACHAT_API_PERS\", verify_ssl_certs=False)\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings_model)\n",
    "\n",
    "# подключаем llm\n",
    "# llm = GigaChat(model='GigaChat-Plus', verify_ssl_certs=False, scope=\"GIGACHAT_API_PERS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Для открытия счета для нотариуса, занимающегося частной практикой, потребуются следующие документы:\\n1. Документ, удостоверяющий личность.\\n2. Документ, подтверждающий наделение нотариуса полномочиями (назначение на должность), выдаваемый органами юстиции субъектов Российской Федерации.\\n3. Адрес места жительства (регистрации) или места пребывания.\\n4. Контактная информация.\\n5. Выписка из ЕГРИП.\\n6. Информация о страховом номере индивидуального лицевого счета застрахованного лица в системе.\\n\\nНотариус может быть иностранцем, при этом ему также потребуется предоставить документ, подтверждающий его право на пребывание (проживание) в Российской Федерации, если это предусмотрено законодательством.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={'k': 25}\n",
    ")\n",
    "\n",
    "# CohereRerank\n",
    "compressor = CohereRerank()\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=retriever\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Вы являетесь помощником в выполнении поиска ответов на вопросы. Используйте приведенные ниже фрагменты извлеченного контекста, чтобы ответить на вопрос. Если вы не знаете ответа, просто скажите, что вы не знаете.\n",
    "        Question: {question} \n",
    "        Context: {context} \n",
    "        Answer:\"\"\")\n",
    "\n",
    "\n",
    "rag_chain_compressor = (\n",
    "    {\"context\": compression_retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "response = rag_chain_compressor.invoke(\"Какие документы потребуются, если открывать счет для нотариуса, занимающегося частной практикой? Может ли нотариус быть иностранцем при этом?\")\n",
    "# response = rag_chain_compressor.invoke(\"На какой срок выдается эта доверенность? Можно ли ее передоверить другому лицу?\")\n",
    "response\n",
    "# rag_chain.invoke(\"При принятии пользовательских соглашений, кому еще попадают мои данные?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка Датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Загрузка данных\n",
    "df = pd.read_csv('../dataset.csv')\n",
    "\n",
    "# Функция для обработки одного запроса с учетом задержки\n",
    "def process_question(question):\n",
    "    answer = rag_chain_compressor.invoke(question.strip())\n",
    "    time.sleep(3)  # Ждать n секунд перед следующим запросом\n",
    "    return answer\n",
    "\n",
    "# Применение функции к каждому вопросу\n",
    "df['answer'] = df['question'].apply(process_question)\n",
    "\n",
    "# Отображение результатов\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Время - 6 минут 43 секунды"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../rag_answer/rag_step_retriever/html_split/rag_compressor_rerank.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variant 2 co.rerank\n",
    "![structure.png](../Schemes/Retrieval_rerank.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`co.rerank` используется для повторного ранжирования списка документов на основе их релевантности к запросу. Этот метод обычно применяется после первоначального поиска, чтобы улучшить порядок документов по их значимости.\n",
    "\n",
    "### Пример работы co.rerank:\n",
    "\n",
    "1. **Поиск документов**: Сначала документы ищутся с помощью `retriever`.\n",
    "2. **Повторное ранжирование**: `co.rerank` применяется к найденным документам для их повторного упорядочивания на основе релевантности к запросу.\n",
    "3. **Возвращение документов**: Возвращаются документы в новом порядке, основанном на результатах повторного ранжирования."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from necessity import *\n",
    "\n",
    "# LangSmith\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"TEST_FINAL_RERANK\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# получаем смысловую разбивку всех документов\n",
    "# splits = split_documents_my_html()\n",
    "splits = split_documents_html(chunk_size=1000, chunk_overlap=100)\n",
    "# splits = split_documents_standart(chunk_size=1000, chunk_overlap=100)\n",
    "\n",
    "# индексируем\n",
    "# embeddings_model = GigaChatEmbeddings(scope=\"GIGACHAT_API_PERS\", verify_ssl_certs=False)\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # подключаем llm\n",
    "# llm = GigaChat(model='GigaChat-Plus', verify_ssl_certs=False, scope=\"GIGACHAT_API_PERS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# получаем только уникальные документы из всего списка\n",
    "def get_unique_documents(documents):\n",
    "    unique_documents = []\n",
    "    seen_contents = set()\n",
    "\n",
    "    for doc in documents:\n",
    "        content = doc.page_content\n",
    "        if content not in seen_contents:\n",
    "            unique_documents.append(doc)\n",
    "            seen_contents.add(content)\n",
    "\n",
    "    return unique_documents\n",
    "\n",
    "# по списку документов получаем определенный с page_content=target_page_content\n",
    "def get_document_by_content(documents, target_page_content):\n",
    "    for doc in documents:\n",
    "        if doc.page_content == target_page_content:\n",
    "            return doc\n",
    "        \n",
    "\n",
    "# Определяем функцию rerank_doc\n",
    "def rerank_doc(query: str, top_n: int):\n",
    "    retrieved_docs = retriever.invoke(query)\n",
    "    unique_docs = get_unique_documents(retrieved_docs)\n",
    "    \n",
    "    # Rerank documents\n",
    "    rerank_results = co.rerank(\n",
    "        query=query, \n",
    "        documents=[doc.page_content for doc in unique_docs], \n",
    "        top_n=top_n, \n",
    "        model=\"rerank-multilingual-v3.0\",\n",
    "        return_documents=True\n",
    "    )\n",
    "    \n",
    "    reranked_docs = []\n",
    "    \n",
    "    for info in rerank_results.results:\n",
    "        doc = get_document_by_content(unique_docs, info.document.text)\n",
    "        doc.metadata['relevance_score'] = info.relevance_score\n",
    "        reranked_docs.append(doc)\n",
    "        \n",
    "    return reranked_docs\n",
    "\n",
    "# Определяем функцию для ранжирования документов\n",
    "def rerank_retriever(query):\n",
    "    return rerank_doc(query, top_n=4)\n",
    "\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={'k': 25}\n",
    ")\n",
    "\n",
    "# Определяем шаблон для запроса\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "        Вы являетесь экспертом в области знаний пользовательских соглашений для банка Tinkoff и помогаете отвечать на вопросы.\\n\n",
    "        Я собираюсь задать вам вопрос. Ваш ответ должен быть исчерпывающим и основываться на следующем контексте (контекст хранится в Context), если он уместен. \\n\n",
    "        Отвечайте от лица представителя Банка и не уходите от темы, ответ должен быть не коротким, а полным.\n",
    "        \n",
    "        Question: {question} \n",
    "        Context: {context} \n",
    "        Answer:\"\"\")\n",
    "\n",
    "\n",
    "# Создаем новую RAG цепочку с использованием rerank_retriever\n",
    "rag_chain_rerank = (\n",
    "    {\"context\": rerank_retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Пример использования новой цепочки\n",
    "# response = rag_chain_rerank.invoke(\"Какие документы потребуются, если открывать счет для нотариуса, занимающегося частной практикой? Может ли нотариус быть иностранцем при этом?\")\n",
    "# response = rag_chain_rerank.invoke(\"Какой минимум страховой выплаты мне вернут, если моя страховая сумма = 50 000 долларов?\")\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Для открытия счета нотариуса, занимающегося частной практикой, необходимо предоставить следующие документы:\n",
      "\n",
      "1. Документ, удостоверяющий личность и указанный в пункте 1.4 настоящего Перечня.\n",
      "2. Документ, подтверждающий наделение нотариуса полномочиями (назначение на должность), выдаваемый органами юстиции субъектов Российской Федерации, в соответствии с законодательством Российской Федерации.\n",
      "3. Адрес места жительства (регистрации) или места пребывания (если его нельзя установить из документа, удостоверяющего личность, а также если адрес места жительства (регистрации) или места пребывания не совпадают).\n",
      "4. Контактная информация (например, номер телефона, факса, адрес электронной почты, почтовый адрес (при наличии).\n",
      "5. Выписка из ЕГРИП. Банком может быть принята копия выписки, заверенная регистрирующим органом. Выписка считается действительной для предоставления в Банк в течение 30 (тридцати) календарных дней с даты ее выдачи и должна содержать актуальные сведения на дату ее предоставления.\n",
      "\n",
      "Ответ на второй вопрос: Да, нотариус может быть иностранцем при открытии счета в банке Tinkoff. Однако, для этого ему необходимо предоставить дополнительные документы, подтверждающие его статус и право на осуществление деятельности в России.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain_rerank.invoke(\"Какие документы потребуются, если открывать счет для нотариуса, занимающегося частной практикой? Может ли нотариус быть иностранцем при этом?\")\n",
    "# response = rag_chain_rerank.invoke(\"Какой минимум страховой выплаты мне вернут, если моя страховая сумма = 50 000 долларов?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод как меняются индексы "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={'k': 25}\n",
    ")\n",
    "\n",
    "def compare(query: str, top_n: int):\n",
    "    retrieved_docs = retriever.invoke(query)\n",
    "    \n",
    "    print(f\"Unique documents count: {len(retrieved_docs)}\")\n",
    "    \n",
    "    print('Query:', query)\n",
    "    # добавляем индексацию в метадату\n",
    "    for idx, doc in enumerate(retrieved_docs):\n",
    "        doc.metadata[\"initial_position\"] = idx\n",
    "\n",
    "    # Create a mapping from document content to its position\n",
    "    content_to_initial_position = {doc.page_content: doc.metadata[\"initial_position\"] for doc in retrieved_docs}\n",
    "    \n",
    "    # Rerank documents\n",
    "    rerank_results = co.rerank(\n",
    "        query=query, \n",
    "        documents=[doc.page_content for doc in retrieved_docs], \n",
    "        top_n=top_n, \n",
    "        model=\"rerank-multilingual-v3.0\",\n",
    "        return_documents=True\n",
    "    )\n",
    "    \n",
    "    # Compare order change\n",
    "    original_docs = []\n",
    "    reranked_docs = []\n",
    "    \n",
    "    for new_position, info in enumerate(rerank_results.results):\n",
    "        original_position = content_to_initial_position[info.document.text]\n",
    "        print(f\"{original_position} -> {new_position}\")\n",
    "        if new_position != original_position:\n",
    "            original_docs.append([original_position, info.document.text])\n",
    "            reranked_docs.append([new_position, retrieved_docs[new_position].page_content])\n",
    "        \n",
    "\n",
    "    for orig, rerank in zip(original_docs, reranked_docs):\n",
    "        print(f\"ORIGINAL {orig[0]}\\n{orig[1]}\\nRERANKED {rerank[0]}\\n{rerank[1]}\\n---------------\")\n",
    "        \n",
    "    return rerank_results\n",
    "\n",
    "a = compare(\"Какой минимум страховой выплаты мне вернут, если моя страховая сумма = 50 000 долларов?\", 25)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка Датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giga generation stopped with reason: blacklist\n",
    "ReadTimeout: The read operation timed out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Загрузка данных\n",
    "df = pd.read_csv('../dataset.csv')\n",
    "\n",
    "# # Функция для обработки одного запроса с учетом задержки\n",
    "# def process_question(question):\n",
    "#     answer = rag_chain_rerank.invoke(question.strip())\n",
    "#     # time.sleep(3)  # Ждать n секунд перед следующим запросом\n",
    "#     return answer\n",
    "\n",
    "# # Применение функции к каждому вопросу\n",
    "# df['answer'] = df['question'].apply(process_question)\n",
    "\n",
    "df['answer'] = df['question'].apply(lambda x: rag_chain_rerank.invoke(x.strip()))\n",
    "\n",
    "# Отображение результатов\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../rag_answer/rag_step_retriever/html_split/rag_rerank_gpt_3.5.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сравнение двух подходов\n",
    "\n",
    "- **`compression_retriever.get_relevant_documents(query)`**: Этот метод не просто повторно ранжирует документы, а также извлекает и сжимает наиболее важные части каждого документа, предоставляя сжатую, но релевантную информацию.\n",
    "- **`co.rerank(query, documents)`**: Этот метод сохраняет оригинальные документы и только изменяет порядок их следования на основе их релевантности к запросу."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
